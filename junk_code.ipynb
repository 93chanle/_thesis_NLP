{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if all docs only contain ASCII letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_docs = []\n",
    "for doc in docs:\n",
    "    prep_doc = ''\n",
    "    for sentence in doc:\n",
    "        sentence = preprocess_text(sentence) # merge_punctuation(sentence)\n",
    "        print(sentence)\n",
    "        prep_doc = ' '.join([prep_doc, sentence])\n",
    "\n",
    "    prep_docs.append(prep_doc)\n",
    "\n",
    "# for idx, prep_doc in enumerate(prep_docs):\n",
    "#     print(f'Doc {idx} is ACSII: {prep_doc.isascii()}')\n",
    "\n",
    "[idx for idx, prep_doc in enumerate(prep_docs) if prep_doc.isalnum() == False]\n",
    "\n",
    "# [print(prep_doc) for prep_doc in enumerate(prep_doc) if prep_doc.isascii() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort corpus vocab and dump to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vocab = dict(sorted(corpus_vocab.items()))\n",
    "\n",
    "len(corpus_vocab)\n",
    "\n",
    "print(corpus_vocab)\n",
    "\n",
    "import json\n",
    "with open('corpus_vocab.json', 'w') as f:\n",
    "    json.dump(corpus_vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "BERT_preprocessing_tokenizer = \"bert-base-uncased\"\n",
    "BERT_model = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_preprocessing_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'While and as well as or operator needs two operands, which may evaluate to true or false, not operator needs one operand evaluating to true or false.'\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence = tokenizer.tokenize(marked_text)\n",
    "\n",
    "len(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def get_bert_embedding_input(sentence):\n",
    "#     tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "#     index_tokens = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "#     tokens_tensor = torch.tensor([index_tokens])\n",
    "#     segments_tensor = torch.ones(len(tokenized_sentence))\n",
    "\n",
    "#     return tokenized_sentence, index_tokens, tokens_tensor, segments_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSentenceEmbedding:\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = sentence\n",
    "        self.tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "        self.index_tokens = tokenizer.convert_tokens_to_ids(self.tokenized_sentence)\n",
    "        self.tokens_tensor = torch.tensor([self.index_tokens])\n",
    "        self.segments_tensor = torch.tensor([[1 for _ in self.tokenized_sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = BertSentenceEmbedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.segments_tensor\n",
    "# s.index_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(s.tokens_tensor, s.segments_tensor)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\93cha\\.conda\\envs\\thesis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = asarray(a).shape\n",
      "c:\\Users\\93cha\\.conda\\envs\\thesis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.shape(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "1\n",
      "20\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(hidden_states)) # Number of layers in BERT models, including the inout embeddings\n",
    "print(len(hidden_states[0])) # Number of batches (sentences) input\n",
    "print(len(hidden_states[0][0])) # Number of tokens in sentence\n",
    "print(len(hidden_states[0][0][0])) # Number of hidden units / features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4174e-01, -2.3037e-01,  1.0960e-02,  1.4319e-01, -2.8272e-01,\n",
       "         1.0180e-01,  5.5519e-01, -5.4578e-02, -2.2493e-01, -8.6961e-01,\n",
       "         4.4585e-01,  1.3074e-01, -8.0233e-02, -2.3877e-01, -4.7602e-01,\n",
       "         4.5088e-01,  2.8182e-01, -7.5689e-02, -4.3809e-01,  1.3318e-02,\n",
       "        -4.8195e-01, -6.3182e-01,  2.1935e-01,  3.7190e-01,  2.3699e-01,\n",
       "         1.7386e-01, -4.3828e-01,  1.8428e-01, -3.6722e-01,  4.6221e-01,\n",
       "        -3.2307e-01, -5.2181e-02,  1.2818e-01, -1.8686e-02,  1.1297e-01,\n",
       "         2.1369e-01, -6.5989e-01,  1.6764e-01, -1.2653e-02,  8.2431e-01,\n",
       "        -7.1396e-02,  4.1277e-01, -2.8675e-01,  6.0078e-01, -1.8392e-01,\n",
       "        -2.3079e-01, -3.5267e+00,  3.7276e-01,  5.7021e-01,  1.4452e-02,\n",
       "         2.8992e-01,  3.2949e-01,  6.9618e-02,  8.4421e-01,  2.4687e-02,\n",
       "        -4.9501e-01,  3.0071e-01, -2.1781e-01, -3.5601e-01, -2.6869e-01,\n",
       "        -7.0847e-02,  7.6872e-01, -6.4508e-01, -1.7380e-01,  2.9230e-01,\n",
       "        -1.3748e-01, -1.9912e-01, -4.6313e-01, -1.3239e-01,  1.9870e-01,\n",
       "        -3.2241e-01, -1.1026e-01,  4.4988e-01,  2.9580e-02,  1.0689e-01,\n",
       "         1.8970e-02, -5.5220e-01, -1.7140e-01, -2.5088e-01,  4.8716e-01,\n",
       "        -3.3721e-02,  5.7893e-02, -1.3846e-01, -1.4032e-01, -1.1956e-04,\n",
       "        -1.8772e-02, -1.0873e-01, -1.1554e-01, -6.2219e-01,  7.3347e-02,\n",
       "        -7.0049e-01, -8.1885e-02, -9.3223e-02,  4.4226e-01,  1.0907e-01,\n",
       "         1.0226e-01, -2.2504e-02, -1.0883e-01,  6.2519e-01, -5.2455e-01,\n",
       "         2.3530e-01,  4.4094e-01, -5.0838e-01,  1.6800e-01,  3.0152e-02,\n",
       "         1.3196e-01, -1.6237e-01,  4.1877e-01,  3.0544e-01,  1.9125e-01,\n",
       "         7.0412e-01,  4.9470e-01,  3.8865e-01, -1.6198e-01,  2.0240e-01,\n",
       "        -6.9675e-01,  4.0690e-01,  5.4156e-01, -1.4652e-01,  9.9636e-02,\n",
       "        -5.2210e-01,  1.4297e+00, -6.0284e-01,  1.7936e-01, -2.3469e-01,\n",
       "        -3.2784e-01, -2.2355e-01,  2.6114e-01,  2.0897e-01,  3.2496e-01,\n",
       "        -3.5889e-01,  3.8758e-01, -9.0533e-02, -6.4424e-01,  4.6759e-02,\n",
       "         1.6644e-01, -3.4536e-01, -1.4612e-02, -2.5368e-01,  3.3907e+00,\n",
       "        -2.5959e-01, -6.0861e-01, -6.9914e-02,  1.8443e-01, -3.9501e-02,\n",
       "        -1.8708e+00, -2.3978e-01,  6.8564e-02, -3.6860e-01,  3.2130e-01,\n",
       "        -5.2882e-01,  2.2351e-01, -5.0010e-01, -5.4615e-01, -3.2532e-01,\n",
       "        -4.8225e-01,  3.7634e-01, -7.1772e-01,  5.3005e-01, -4.4500e-01,\n",
       "        -5.6795e-02,  3.4053e-01,  4.6688e-02, -4.7767e-01,  8.8018e-02,\n",
       "         2.1506e-01, -1.6961e-01, -2.9201e-01,  1.0643e+00,  4.2106e-01,\n",
       "        -5.3623e-02, -1.5934e-01, -4.7465e-01, -5.1015e-01, -7.9877e-02,\n",
       "        -3.2999e-02, -3.5625e-01, -3.9942e-01,  1.4563e-01, -1.0225e-01,\n",
       "         4.2611e-01,  1.6840e-01, -6.7840e-01, -5.8383e-02,  1.6478e-01,\n",
       "        -3.4337e-01, -4.1294e-01, -1.8250e-01,  3.8668e-01, -2.9802e-01,\n",
       "         2.1573e-01, -6.8362e-02, -1.4152e-01, -5.9066e-01,  4.8134e-01,\n",
       "        -3.2461e-01,  1.3959e-01,  4.5920e-01, -2.1488e-03,  3.7067e-01,\n",
       "        -4.3498e-01,  1.9677e-01,  1.6955e-01, -1.0204e-01,  6.6782e-01,\n",
       "         1.3428e-01,  3.7640e-02,  2.0289e-01, -4.6122e-01,  2.2654e-01,\n",
       "         2.6433e-01,  1.1197e-01, -3.7928e-02,  2.0427e-01, -5.0602e-01,\n",
       "        -9.5237e-01, -1.2954e-01,  4.4272e-01, -1.7378e-01,  3.2038e-01,\n",
       "         1.2323e-01,  1.8350e-01, -3.2535e-01,  6.7595e-01,  3.9368e-01,\n",
       "         8.2291e-01, -3.8728e-01,  1.7876e-01,  1.5984e-01, -6.1393e-01,\n",
       "         7.1793e-02,  5.5970e-01,  3.6989e-01,  6.5617e-01,  1.2556e-01,\n",
       "         3.6543e-02, -6.1012e-01, -2.1865e-01,  2.2871e-02, -2.0726e-01,\n",
       "         8.8485e-02,  5.3965e-02,  3.0315e-01,  1.8952e-01,  1.7614e-01,\n",
       "        -4.6139e-02, -3.0990e-02, -5.8669e-02, -5.4472e-01,  2.0790e-01,\n",
       "        -1.2771e-01, -2.5471e-01, -4.9056e-01, -2.1184e-01,  1.9476e-01,\n",
       "        -5.4652e-03,  3.0337e-01,  3.1079e-01, -2.7450e-01,  2.1213e-01,\n",
       "         5.1115e-01, -5.8873e-01,  1.6670e-01,  8.8536e-01,  5.0290e-01,\n",
       "        -1.3654e-01,  4.2889e-01, -5.7154e-01,  1.0638e-02, -7.1419e-02,\n",
       "         4.7938e-01,  7.6392e-02,  3.0848e-01,  4.3266e-01, -4.9664e-01,\n",
       "        -7.2152e-01, -2.5165e-01,  5.9556e-01, -2.0467e-01,  9.6115e-02,\n",
       "         8.6923e-02, -6.3399e-01,  7.5728e-01, -2.8530e-01,  4.6902e-01,\n",
       "         1.4450e-01,  2.5507e-01,  1.7300e-01,  5.0170e-01,  3.7190e-01,\n",
       "        -3.1610e-01, -3.5799e-01, -6.8946e-01,  3.1679e-01, -2.3746e-01,\n",
       "         4.6739e-01,  3.5195e-01,  8.7388e-02, -3.6927e-01, -7.3693e-01,\n",
       "         3.8955e-02, -6.8104e-02, -2.2939e-01,  4.8357e-01, -1.2617e+00,\n",
       "         1.2116e-01, -3.7224e-01,  3.8403e-01, -1.1389e+01,  6.3373e-02,\n",
       "         3.3309e-01, -8.8813e-02,  2.5259e-02,  3.7521e-01,  5.9607e-01,\n",
       "        -2.8211e-02,  3.8712e-01,  4.3239e-01, -4.5377e-02,  2.5330e-01,\n",
       "        -1.0737e-01, -2.1929e-01,  3.0963e-01,  2.6708e-01,  6.9897e-01,\n",
       "         2.6539e-02,  1.0701e-01, -2.1523e-01,  2.2927e-01,  3.9774e-01,\n",
       "        -3.9853e-01, -2.1923e-01, -1.0509e-01,  5.1870e-01, -7.2142e-01,\n",
       "         2.1771e-01,  3.5056e-01,  5.1303e-02,  1.7687e-01, -2.9421e-02,\n",
       "        -8.9614e-01,  3.4478e-01, -2.4804e-01, -2.6817e-01, -7.8059e-02,\n",
       "        -1.1340e-01,  1.6271e-01, -2.1973e-01,  2.5739e-01, -4.4087e-01,\n",
       "         1.1522e-01, -5.1149e-01,  3.8972e-01, -5.9734e-02,  1.7440e-01,\n",
       "         3.1093e-01, -8.4003e-02, -3.7747e-01, -6.0464e-01,  3.8476e-01,\n",
       "         5.5621e-01, -3.9353e-01,  4.6828e-01, -5.1762e-01,  1.8606e-01,\n",
       "         5.3933e-01,  6.6782e-02, -4.3143e-01, -6.3647e-01,  7.0378e-02,\n",
       "         2.3040e-01, -2.8016e-01, -6.7452e-02, -5.6842e-01,  2.3921e-03,\n",
       "        -9.6826e-02, -3.2022e-02, -1.0525e-01, -5.0112e-02,  4.6190e-01,\n",
       "        -1.2118e-01, -2.1128e+00, -4.1583e-01,  1.9989e-02,  8.1176e-02,\n",
       "         2.8494e-02,  4.3435e-01,  2.3428e-01, -1.3244e-02, -6.1061e-01,\n",
       "        -1.3956e-02, -5.7877e-01,  3.7225e-01,  8.2359e-02, -2.1096e-02,\n",
       "         2.1446e-01,  2.2998e-01,  2.3890e-01, -7.6388e-01,  2.8282e-01,\n",
       "        -3.7000e-01,  1.8402e-01, -2.3137e-01,  1.7160e-01,  2.6603e-01,\n",
       "         4.2835e-03,  4.0440e-01,  3.7357e-01, -2.3894e-01, -2.4612e-01,\n",
       "         8.1886e-02,  3.5235e-01,  4.5671e-01,  3.5119e-02, -5.9251e-02,\n",
       "        -1.6131e-01, -7.0111e-01,  5.2156e-02,  1.3421e-01,  8.4478e-01,\n",
       "         2.4653e-01,  1.3879e-01,  8.9182e-01, -1.1116e-02,  1.2056e-01,\n",
       "        -3.7546e-01,  5.4053e-01, -4.4782e-01,  3.1685e-01,  1.8883e-01,\n",
       "        -4.4501e-01, -5.3486e-01,  4.0841e-01, -1.7015e-01, -3.0838e-01,\n",
       "         3.4966e-01,  5.0943e-01,  1.4003e-01, -1.4308e-01, -2.4693e-02,\n",
       "         1.6694e-01,  8.5474e-03, -3.5337e-01,  6.0919e-01, -4.0897e-01,\n",
       "         3.1535e-01,  4.4290e-01,  6.5622e-01,  3.3279e-01, -5.0223e-01,\n",
       "        -5.1426e-01,  6.0835e-01,  1.9487e-01,  1.4041e-01, -1.8076e-01,\n",
       "         5.3515e-01,  2.6758e-01, -3.1317e-02, -1.9246e-01, -2.4907e-01,\n",
       "         3.1461e-01, -2.8855e-01,  3.4844e-01, -2.2314e-01,  3.4646e-01,\n",
       "         3.4477e-01,  1.3004e-01, -2.1633e-01, -2.9226e-01, -9.7330e-02,\n",
       "        -1.4613e+00,  3.3589e-02,  3.5675e-01, -7.5446e-02,  1.8159e-01,\n",
       "         2.0745e-01, -1.1423e-01, -3.5842e-01,  6.0630e-01,  4.6013e-01,\n",
       "         1.0434e-01,  2.6825e-01, -7.0191e-01,  5.6899e-01,  4.2429e-01,\n",
       "         2.3324e-01, -5.6633e-01,  3.8173e-01,  4.8503e-01,  1.4195e-01,\n",
       "        -6.5003e-01,  7.2217e-01,  2.4123e-01,  3.3875e-01, -2.3652e-01,\n",
       "         6.1398e-02,  1.8592e-01, -1.3619e-01,  1.3284e-01, -1.9859e-01,\n",
       "         4.3399e-01,  2.7417e-01,  1.1952e-01,  2.2509e-01,  4.8453e-02,\n",
       "         3.7147e-01,  6.8231e-02,  6.0822e-02, -1.0253e-01,  3.6226e-02,\n",
       "         1.6112e-01,  2.0060e-01,  2.9627e-01,  1.4209e-01, -1.8664e-02,\n",
       "         8.2154e-02,  4.2623e-01,  3.3214e-01,  2.1539e-01,  2.2646e-01,\n",
       "         2.3050e-03,  2.6854e-01,  4.3957e-01, -7.7699e-01, -2.0128e-01,\n",
       "         3.1773e-01, -1.9805e-02,  4.4418e-01, -2.8287e-01, -1.5078e-01,\n",
       "         1.8836e-01, -2.5073e-02, -1.7602e-01,  5.1273e-02,  1.2949e-01,\n",
       "        -6.7537e-01,  2.1543e-01, -6.6590e-01, -2.3496e-02, -4.5385e-01,\n",
       "        -3.6528e-02, -3.9832e-02,  2.5812e-01, -2.3977e-01,  5.7738e-01,\n",
       "         1.0899e+00,  3.3157e-01,  3.7359e-01, -1.2061e-01, -3.2013e-01,\n",
       "        -1.0821e-01, -5.2341e-01,  4.2218e-01,  2.1305e-01,  3.7736e-01,\n",
       "         1.5479e-01,  2.1403e-01, -3.9350e-01,  7.4261e-01,  4.4696e-02,\n",
       "         3.3801e-01,  1.4430e-01,  3.9601e-01,  2.6599e-01, -3.9602e-01,\n",
       "        -4.8474e-01,  1.1960e-01,  3.4824e-01, -5.1326e-01, -4.7954e-01,\n",
       "        -6.4311e-01, -4.8045e-01,  1.9904e-01, -2.5261e-01,  2.0057e-01,\n",
       "        -6.1561e-02,  3.5755e-01, -5.7841e-01,  3.5883e-01,  5.8171e-02,\n",
       "        -1.9954e-01,  4.0213e-01,  1.7943e-02,  5.9678e-01,  4.7641e-01,\n",
       "         1.7225e-01, -6.1413e-01, -8.5242e-02,  2.4026e-01,  3.1987e-01,\n",
       "        -5.5466e-01, -8.9364e-02, -1.8529e-01,  4.1296e-02,  2.4997e-01,\n",
       "         3.9269e-01, -4.8001e-01,  1.7182e-01,  5.9090e-01,  9.4308e-02,\n",
       "         1.6658e-01,  1.0744e-01,  3.2290e-01,  4.7366e-01,  3.6836e-01,\n",
       "         7.8504e-02, -3.7400e-02, -3.4057e-02, -1.8917e-01,  5.8063e-01,\n",
       "        -7.5594e-01, -1.1043e-01,  1.2295e-01,  2.7209e-01, -4.7576e-01,\n",
       "        -2.3584e-01,  2.9881e-01,  1.4048e-01,  5.4142e-01, -2.5304e-01,\n",
       "         1.7801e-01,  2.0961e-01, -1.8476e-01,  4.3201e-01, -3.7817e-01,\n",
       "         1.8259e-01,  1.2228e-01, -7.6857e-02,  3.9097e-01, -6.3806e-01,\n",
       "         1.2686e-01, -4.8977e-01, -6.4168e-01,  3.5995e-01,  2.1695e-01,\n",
       "        -6.9705e-01,  3.1974e-02, -5.7007e-01,  3.4167e-01, -3.1714e-01,\n",
       "        -8.0678e-02, -6.2937e-02, -5.2084e-01, -3.2453e-01, -6.7053e-01,\n",
       "         5.9041e-01,  1.9258e-01, -3.8499e-01,  5.5418e-01, -6.2196e-02,\n",
       "        -4.2467e-01, -8.2740e-01, -2.9923e-01,  1.1206e-01, -7.6482e-02,\n",
       "         2.3597e-01, -1.6810e-01,  1.0705e-01, -3.0078e-02, -6.5089e-01,\n",
       "         7.8348e-01, -5.3443e-01, -8.4686e-02, -6.7340e-01,  1.8726e-01,\n",
       "        -6.1045e-01,  1.0116e-01,  3.9643e-03,  4.3888e-01, -5.9316e-01,\n",
       "         2.8030e-01,  8.9000e-02,  2.4861e-01,  8.8534e-02,  8.6635e-02,\n",
       "        -1.9673e-01,  5.6291e-01,  4.6350e-01,  1.0209e-01,  4.6309e-01,\n",
       "         5.6383e-01,  4.2203e-02, -4.1932e-01,  1.0077e-01, -3.1468e-01,\n",
       "         2.7121e-01,  3.6126e-01,  2.0227e-01, -3.3846e-01,  3.1023e-01,\n",
       "        -4.7626e-02, -3.2028e-01, -7.0005e-02,  5.5451e-01, -6.0596e-02,\n",
       "         9.5803e-02, -4.8114e-01, -1.3661e-01, -1.9110e-01, -4.3733e-01,\n",
       "         1.4739e-01, -7.8789e-02,  1.4466e-01,  3.9474e-01, -6.8059e-01,\n",
       "         1.9581e-01,  3.6774e-01, -2.3316e-02, -1.6856e-01,  4.4099e-01,\n",
       "         7.8368e-02, -3.9263e-01, -6.8820e-02, -7.1972e-01, -8.9083e-02,\n",
       "         4.6498e-01, -4.3303e-01,  1.8067e-01, -1.8727e-01, -5.9425e-01,\n",
       "        -1.8005e-01,  1.3444e-01, -2.2218e-01, -4.7858e-01,  3.8525e-01,\n",
       "         2.6756e-01,  1.3839e-01,  5.7163e-02,  2.5081e-01,  1.7623e-01,\n",
       "         2.2274e-01,  3.8609e-01,  6.0873e-01, -4.8054e-01,  3.5970e-01,\n",
       "        -3.7382e-01, -2.4435e-01,  2.0913e-01,  5.7232e-02,  2.1564e-02,\n",
       "        -1.2753e+00, -2.8964e-01,  2.4853e-01, -1.7280e-01,  2.7428e-01,\n",
       "         3.8635e-01, -5.3294e-01, -1.6688e-01, -2.7046e-01,  3.1677e-02,\n",
       "        -2.0566e-01, -1.4379e-01, -5.7584e-01, -1.6371e-02, -1.0120e+00,\n",
       "         4.3914e-01, -4.4505e-01,  4.0372e-02,  5.1481e-01, -1.3840e-01,\n",
       "        -6.2036e-01, -8.3188e-02,  5.4764e-01, -2.9587e-02,  2.2885e-01,\n",
       "        -3.4320e-01,  2.6753e-01,  5.7107e-01])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create / add token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_token_embeddings = {}\n",
    "\n",
    "tokens = ['i', 'love', 'you']\n",
    "\n",
    "token_embeddings = get_token_embeddings(tokens)\n",
    "\n",
    "# doc_token_embeddings = dict(zip(tokens, token_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1019, -0.8678, -0.1187,  ..., -0.0555,  0.3492,  0.7548],\n",
      "        [ 0.7621, -0.1919, -0.1353,  ...,  0.0494,  0.4771,  0.4659],\n",
      "        [ 0.4800, -0.1612, -0.7899,  ..., -0.5469,  0.8261,  0.3935],\n",
      "        [ 0.4322, -0.5650, -0.4019,  ...,  0.0614,  0.2550,  0.3160],\n",
      "        [ 0.0070, -0.0818, -0.2650,  ..., -0.2173,  0.7020,  0.5809]])\n"
     ]
    }
   ],
   "source": [
    "tokens = ['i', 'like', 'him', 'and', 'you']\n",
    "\n",
    "token_embeddings = get_token_embeddings(tokens)\n",
    "\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = ['i', 'love', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = ['i', 'love', 'you']\n",
    "\n",
    "adj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 1, 'i': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in window:\n",
    "    if token not in adj.keys(): adj[token] = {}\n",
    "    window_temp = window\n",
    "    window_temp.remove(token)\n",
    "    for token_temp in window_temp:\n",
    "        if token_temp not in adj[token].keys():\n",
    "            adj[token][token_temp] =1\n",
    "        else: adj[token][token_temp] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': {}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# window.remove('love')\n",
    "adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f23bbf4ff482c7ba4eb349bb77b97513a7d810cc54a91b10dca8f00361b6308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
